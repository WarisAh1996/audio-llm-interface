<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio LLM Interface</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .recording-controls {
            display: flex;
            gap: 10px;
            margin: 20px 0;
        }
        button {
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
        }
        #recordButton {
            background-color: #ff4444;
            color: white;
        }
        #recordButton.recording {
            background-color: #cc0000;
        }
        .response-section {
            margin-top: 20px;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .transcription-area, .analysis-area {
            margin-top: 20px;
            padding: 15px;
            background-color: #f9f9f9;
            border-radius: 4px;
        }
        .status {
            margin-top: 10px;
            padding: 10px;
            border-radius: 4px;
        }
        .status.uploading {
            background-color: #fff3cd;
            color: #856404;
        }
        .status.processing {
            background-color: #cce5ff;
            color: #004085;
        }
        .status.success {
            background-color: #d4edda;
            color: #155724;
        }
        .status.error {
            background-color: #f8d7da;
            color: #721c24;
        }
        h3 {
            color: #333;
            margin-bottom: 10px;
        }
        .loader {
            display: none;
            margin: 10px 0;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Audio LLM Interface</h1>
        
        <div class="recording-controls">
            <button id="recordButton">Start Recording</button>
        </div>

        <div class="status" id="status">Ready to record...</div>

        <div class="response-section">
            <div class="transcription-area">
                <h3>Transcription:</h3>
                <div id="transcription">No transcription yet</div>
            </div>

            <div class="analysis-area">
                <h3>Psychological Analysis:</h3>
                <div id="modelResponse">No analysis yet</div>
            </div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;

        function updateStatus(message, type) {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = message;
            statusDiv.className = 'status ' + type;
        }

        async function setupRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await sendAudioToServer(audioBlob);
                };

                const recordButton = document.getElementById('recordButton');
                recordButton.addEventListener('click', toggleRecording);
            } catch (err) {
                console.error('Error accessing microphone:', err);
                updateStatus('Error accessing microphone. Please ensure microphone permissions are granted.', 'error');
            }
        }

        function toggleRecording() {
            const recordButton = document.getElementById('recordButton');

            if (!isRecording) {
                audioChunks = [];
                mediaRecorder.start();
                isRecording = true;
                recordButton.textContent = 'Stop Recording';
                recordButton.classList.add('recording');
                updateStatus('Recording in progress...', 'uploading');
            } else {
                mediaRecorder.stop();
                isRecording = false;
                recordButton.textContent = 'Start Recording';
                recordButton.classList.remove('recording');
                updateStatus('Uploading audio...', 'uploading');
            }
        }

        async function sendAudioToServer(audioBlob) {
            try {
                const formData = new FormData();
                formData.append('audio_file', audioBlob, 'recording.webm');

                updateStatus('Uploading audio...', 'uploading');
                
                const response = await fetch('/upload-audio', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                
                if (data.status === 'success') {
                    updateStatus('Processing complete!', 'success');
                    document.getElementById('transcription').textContent = data.transcription || 'No transcription available';
                    document.getElementById('modelResponse').textContent = data.model_output || 'No analysis available';
                } else {
                    throw new Error(data.message || 'Unknown error occurred');
                }
            } catch (error) {
                console.error('Error sending audio:', error);
                updateStatus('Error: ' + error.message, 'error');
            }
        }

        setupRecording();
    </script>
</body>
</html>
